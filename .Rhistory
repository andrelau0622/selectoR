# 安装依赖包
depens <- c('GSEABase', 'GSVA', 'cancerclass', 'mixOmics', 'sparrow', 'sva', 'ComplexHeatmap')
for (i in 1:length(depens)) {
depen <- depens[i]
if (!requireNamespace(depen, quietly = TRUE)) BiocManager::install(depen, update = FALSE)
}
# 101 ####
# 安装并加载必要的包
# 需要在系统中安装python、keras与tensorflow
# 先安装python，随后在命令行中运行：pip install tensorflow、pip install keras（太慢的话可以设置镜像）
install.packages("catboost")
# 101 ####
# 安装并加载必要的包
# 需要在系统中安装python、keras与tensorflow
# 先安装python，随后在命令行中运行：pip install tensorflow、pip install keras（太慢的话可以设置镜像）
install.packages('remotes')
remotes::install_url('https://github.com/catboost/catboost/releases/download/v1.2.5/catboost-R-darwin-universal2-1.2.5.tgz', INSTALL_opts = c("--no-multiarch", "--no-test-load"))
unlink(tempdir(), recursive = TRUE)
library(pROC)
library(ggplot2)
library(keras)
library(dplyr)
library(caret)
library(tensorflow)
library(MASS)
library(class)
library(tree)
library(randomForest)
library(xgboost)
library(glmnet)
library(e1071)
library(ComplexHeatmap)
library(kernlab)
library(gbm)
unlink(tempdir(), recursive = TRUE)
.libPaths( c( .libPaths(), "~/oldLibrary") )
remotes::install_url('https://github.com/catboost/catboost/releases/download/v1.2.5/catboost-R-darwin-universal2-1.2.5.tgz', INSTALL_opts = c("--no-multiarch", "--no-test-load"))
# 101 ####
# 安装并加载必要的包
# 需要在系统中安装python、keras与tensorflow
# 先安装python，随后在命令行中运行：pip install tensorflow、pip install keras（太慢的话可以设置镜像）
install.packages('remotes')
data <- read.csv('/Users/AndreLau/Desktop/MIMIC/全预测/30/data.csv')
# 设置因子型
ordata <- data
colnames(data)
data[,1:12] <- lapply(data[,1:12],as.factor)
# 删除缺失值,可选择插补
# ordata <- na.omit(ordata)
# head(data)
# MICE插补
# data插补
# 创建插补对象
imputed_data <- mice(data, method = "pmm",m = 5)
library(corrplot)
library(glmnet)
library(caret)
library(CBCgrps)
library(nortest)
library(tidyverse)
library(ggpubr)
library(rms)
library(pROC)
library(viridis)
library(mice)
library(plyr)
library(colorspace)
library(VIM)
library(mice)
library(ggplot2)
#### 数据整理（主要在Excel中完成）####
# 载入数据
data <- read.csv('/Users/AndreLau/Desktop/MIMIC/全预测/30/data.csv')
# 设置因子型
ordata <- data
colnames(data)
data[,1:12] <- lapply(data[,1:12],as.factor)
# 删除缺失值,可选择插补
# ordata <- na.omit(ordata)
# head(data)
# MICE插补
# data插补
# 创建插补对象
imputed_data <- mice(data, method = "pmm",m = 5)
# 提取所有插补后的数据集
imputed_data_list <- complete(imputed_data, "all")
# 为每个数据集添加插补标识符列
imputed_data_list <- lapply(seq_along(imputed_data_list), function(i) {
imputed_data_list[[i]]$imputation_id <- i
return(imputed_data_list[[i]])
})
# 合并所有插补后的数据集为data
data <- do.call(rbind, imputed_data_list)
# 删除
column_to_remove <- "imputed_id"
# 从数据框中删除指定列
data <- data[, !(names(data) %in% "imputation_id")]
# 找出缺失值的具体位置
missing_positions <- which(is.na(data), arr.ind = TRUE)
print(missing_positions)
# 检查数据类型，如果有整数，将所有int转化为num
data[,13:77] <- lapply(data[,13:77],as.numeric)
data <- na.omit(data)
imputed_data <- mice(ordata, method = "pmm",m = 5)
# 提取所有插补后的数据集
imputed_data_list <- complete(imputed_data, "all")
# 为每个数据集添加插补标识符列
imputed_data_list <- lapply(seq_along(imputed_data_list), function(i) {
imputed_data_list[[i]]$imputation_id <- i
return(imputed_data_list[[i]])
})
# 合并所有插补后的数据集为data
ordata <- do.call(rbind, imputed_data_list)
# 删除
column_to_remove <- "imputed_id"
# 从数据框中删除指定列
ordata <- ordata[, !(names(ordata) %in% "imputation_id")]
# 检查数据类型，如果有整数，将所有int转化为num
ordata[,13:77] <- lapply(ordata[,13:77],as.numeric)
ordata <- na.omit(ordata)
library(kableExtra)
library(broom)
library(caret)
library(Metrics)
# 设定模型
set.seed(123)
train_control <- trainControl(method = "cv", number = 5)
metric <- "Accuracy"
# 逐步回归模型
# 拟合初始模型
initial_model <- glm(thirtyday_expire_flag ~ ., data = train, family = "binomial")
library(caret)
library(MASS)
library(tidyverse)
# 将目标变量转换为因子型
data$thirtyday_expire_flag <- as.factor(data$thirtyday_expire_flag)
set.seed(123) # 设置随机种子以确保结果可重复
train_index <- createDataPartition(data$thirtyday_expire_flag, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# 训练逻辑回归模型并进行逐步回归特征选择
initial_model <- glm(thirtyday_expire_flag ~ ., data = train_data, family = binomial)
# 使用 stepAIC 进行逐步回归
stepwise_model <- stepAIC(initial_model, direction = "both")
# 打印最终模型的摘要
model_summary <- summary(stepwise_model)
View(model_summary)
model_summary
View(model_summary)
# 提取系数表
coefficients_df <- as.data.frame(model_summary$coefficients)
# 提取变量名称
variables <- rownames(coefficients_df)
# 将变量名称和系数表合并为一个数据框
coefficients_df$Variable <- variables
coefficients_df <- coefficients_df[, c("Variable", "Estimate", "Std. Error", "z value", "Pr(>|z|)")]
View(coefficients_df)
# 将数据框写入 CSV 文件
write.csv(coefficients_df, file = "/Users/AndreLau/Desktop/MIMIC/全预测/30/stepwise_model_summary.csv", row.names = FALSE)
# 根据选中的特征重新训练模型
train_data_selected <- train_data[, c(selected_features, "hospital_expire_flag")]
# 提取选中的特征
selected_features <- names(coef(stepwise_model))[-1] # 排除截距项
# 根据选中的特征重新训练模型
train_data_selected <- train_data[, c(selected_features, "hospital_expire_flag")]
# 根据选中的特征重新训练模型
train_data_selected <- train_data[, c(selected_features, "thirtyday_expire_flag")]
# 根据选中的特征重新训练模型
train_data_selected <- train_data[, c(selected_features, "thirtyday_expire_flag")]
library(VIM)
library(mice)
library(rlang)
library(tidyverse)
library(reshape2)
library(openxlsx)
library(DALEX)
library(readr)
library(gbm)
library(dplyr)
library(caret)
library(ggplot2)
library(pROC)
library(rms)
library(rmda)
library(dcurves)
library(Hmisc)
library(ResourceSelection)
library(DynNom)
library(survey)
library(caret)
library(foreign)
library(plotROC)
library(survival)
library(shapper)
library(iml)
library(e1071)
library(ROCR)
library(corrplot)
library(lattice)
library(Formula)
library(SparseM)
library(survival)
library(riskRegression)
library(pheatmap)
library(fastshap)
library(naivebayes)
library(ingredients)
library(mlr3)
library(table1)
library(tableone)
library(adabag)
library(RColorBrewer)
library(cvms)
library(tibble)
# 设置工作路径
setwd('/Users/AndreLau/Desktop/MLv2.0')
#读取数据
data <- read.csv("data.csv")#替换自己数据(数据第一列为因变量，接下来放分类变量的列，最后放定量变量的列)
colnames(data)#查看数据列名
#查看是否有缺失值
table(is.na(data))
View(data)
#分类变量处理
#变量因子化，只有分类进行因子化(设置哑变量)
data[,1:12] <- lapply(data[,1:12],as.factor)
##划分数据集
set.seed(123)#设置随机数
inTrain<-createDataPartition(y=data[,"thirtyday_expire_flag"], p=0.7, list=F)#划分训练集,设置训练集的比例为0.7
traindata<-data[inTrain,]#提取训练集数据
testdata<-data[-inTrain,]#提取验证集数据
write.csv(traindata,"dev.csv",row.names = F)#保存训练集数据
write.csv(testdata,"vad.csv",row.names = F)#保存验证集数据
x = traindata
# 连续性自变量
x1=colnames(x[,13:ncol(x)])#从14列以后为连续变量
# 分类型自变量
x2=colnames(x[,2:12])#指定分类变量列数，从那一列到那一列
CreateTableOne(data=x)#生成训练集总体的基线表
myVars <- colnames(x[,2:ncol(x)])#所有自变量的列数，不用改的
catVars <- colnames(x[,2:77])#自变量所在的列，修改自己的列数
catVars <- colnames(x[,2:12])#自变量所在的列，修改自己的列数
tab2 <- CreateTableOne(vars = myVars,data = x,factorVars = catVars)#将总体的基线资料表格储存在tab2，才能方便保存
print(tab2,format0ptions=list(big.showAllLevels=TRUE,mark=','))#输出表格
tab2Mat <- print(tab2,quote = FALSE,noSpaces = TRUE,
printToggle = FALSE)
write.csv(tab2Mat,file = '训练集基础特征.csv')
tab3 <- CreateTableOne(vars = myVars,strata = 'thirtyday_expire_flag',       #strata指定因变量(spesis),替换自己变量
data = x,factorVars = catVars)     #比较两组之间的各个变量的差异
print(tab3,showAllLevels=TRUE,format0ptions=list(big.mark=','))    #输出一下
#整理输出，差异表格
tab3Mat <- print(tab3,quote = FALSE,noSpaces = TRUE,
printToggle = FALSE)        #表格化
write.csv(tab3Mat,file = '训练集单因素分析结果.csv')    #保存表格
# 单因素、多因素logistic回归 ####
#install.packages("autoReg")#装包
library(autoReg)#加载包
overall.log <- glm(thirtyday_expire_flag ~ .,data=x,family=binomial) #进行Logistic回归，检验变量是否为发病的危险因素
#“~”前为因变量，“~”后的.代表除了因变量之后所有变量
summary(overall.log)
catVars
#“~”前为因变量，“~”后的.代表除了因变量之后所有变量
summary(overall.log)
model3 <- autoReg(overall.log,uni=TRUE,milti=TRUE,threshold=0.05)#包含单因素和多因素结果
overall.log <- glm(thirtyday_expire_flag ~ .,data=x,family=binomial) #进行Logistic回归，检验变量是否为发病的危险因素
View(overall.log)
model3 <- autoReg(overall.log,uni=TRUE,milti=TRUE,threshold=0.05)#包含单因素和多因素结果
print(dim(uni))
View(tab3)
model3 <- autoReg(overall.log,uni=TRUE,threshold=0.05)#包含单因素和多因素结果
model3 <- autoReg(overall.log,uni=TRUE,multi=FALSE,threshold=0.05)#包含单因素和多因素结果
View(model3)
model3
write.csv(model3,"训练集单因素Logistic回归.csv",row.names = F)
model4 <- autoReg(overall.log,uni=FALSE,multi=TRUE,threshold=0.05)
library(tensorflow)
tf_version <- tf$`__version__`
print(tf_version)
uninstall_tensorflow()
library(reticulate)
virtualenv_remove("your_virtualenv_name")
remove.packages("tensorflow")
devtools::install_version("tensorflow", version = "2.13.0", repos = "http://cran.us.r-project.org")
remove.packages("keras")
devtools::install_version("keras", version = "2.13.0", repos = "http://cran.us.r-project.org")
remove.packages("reticulate")
library(devtools)
install_version("reticulate", version = "1.31")
library(tensorflow)
tf_version <- tf$`__version__`
print(tf_version)
library(reticulate)
py_discover_config()
library(tensorflow)
tf_version <- tf$`__version__`
print(tf_version)
library(keras)
tf_version <- tf$`__version__`
print(tf_version)
library(pROC)
library(ggplot2)
library(keras)
remove.packages("tensorflow")
library(reticulate)
install_tensorflow(version = "2.13.0")
# 清理 R 临时文件
unlink(".RData", force = TRUE)
unlink(".Rhistory", force = TRUE)
# 卸载 tensorflow 包
remove.packages("tensorflow")
library(devtools)
create("selectoR")
library(roxygen2)
# 生成文档和 NAMESPACE 文件
roxygen2::roxygenize()
# 生成文档和 NAMESPACE 文件
setwd('/Users/AndreLau/Desktop/MLv2.0/selectoR')
roxygen2::roxygenize()
# 在包的根目录下运行
devtools::document()
devtools::check()
devtools::build()
